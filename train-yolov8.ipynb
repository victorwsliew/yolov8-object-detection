{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. make sure we have access to use GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. install `ultralytics` and [dependencies](https://github.com/ultralytics/ultralytics/blob/main/requirements.txt) and check software and hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install ultralytics\n",
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. create train-val split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "%pip install tqdm --upgrade\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. connect to google drive and mount it (for dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. define files path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path_img = \"./yolo_data/images/train/\"\n",
    "train_path_label = \"./yolo_data/labels/train/\"\n",
    "val_path_img = \"./yolo_data/images/val/\"\n",
    "val_path_label = \"./yolo_data/labels/val/\"\n",
    "test_path = \"./yolo_data/test\"\n",
    "\n",
    "# dataset location in drive\n",
    "dataset_folder = '/content/drive/MyDrive/yolov8/ai-trackware'\n",
    "dataset_source = dataset_folder +'/data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. split dataset into train and test set (80% to train and 20% to test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(path,neg_path=None, split = 0.3):\n",
    "    print(\"------ PROCESS STARTED -------\")\n",
    "\n",
    "\n",
    "    files = list(set([name[:-4] for name in os.listdir(path)])) ## removing duplicate names i.e. counting only number of images\n",
    "    \n",
    "\n",
    "    print (f\"--- This folder has a total number of {len(files)} images---\")\n",
    "    random.seed(42)\n",
    "    random.shuffle(files)\n",
    "\n",
    "    test_size = int(len(files) * split)\n",
    "    train_size = len(files) - test_size\n",
    "\n",
    "    ## creating required directories\n",
    "\n",
    "    os.makedirs(train_path_img, exist_ok = True)\n",
    "    os.makedirs(train_path_label, exist_ok = True)\n",
    "    os.makedirs(val_path_img, exist_ok = True)\n",
    "    os.makedirs(val_path_label, exist_ok = True)\n",
    "\n",
    "    \n",
    "    ### ----------- copying images to train folder\n",
    "    for filex in tqdm(files[:train_size]):\n",
    "      if filex == 'classes':\n",
    "          continue\n",
    "      shutil.copy2(path + filex + '.jpg',f\"{train_path_img}/\" + filex + '.jpg' )\n",
    "      shutil.copy2(path + filex + '.txt', f\"{train_path_label}/\" + filex + '.txt')\n",
    "        \n",
    "    \n",
    "\n",
    "    print(f\"------ Training data created with 70% split {len(files[:train_size])} images -------\")\n",
    "    \n",
    "    if neg_path:\n",
    "        neg_images = list(set([name[:-4] for name in os.listdir(neg_path)])) ## removing duplicate names i.e. counting only number of images\n",
    "        for filex in tqdm(neg_images):\n",
    "            shutil.copy2(neg_path+filex+ \".jpg\", f\"{train_path_img}/\" + filex + '.jpg')\n",
    "            \n",
    "        print(f\"------ Total  {len(neg_images)} negative images added to the training data -------\")\n",
    "    \n",
    "        print(f\"------ TOTAL Training data created with {len(files[:train_size]) + len(neg_images)} images -------\")\n",
    "    \n",
    "\n",
    "\n",
    "    ### copytin images to validation folder\n",
    "    for filex in tqdm(files[train_size:]):\n",
    "      if filex == 'classes':\n",
    "          continue\n",
    "      # print(\"running\")\n",
    "      shutil.copy2(path + filex + '.jpg', f\"{val_path_img}/\" + filex + '.jpg' )\n",
    "      shutil.copy2(path + filex + '.txt', f\"{val_path_label}/\" + filex + '.txt')\n",
    "\n",
    "    print(f\"------ Testing data created with a total of {len(files[train_size:])} images ----------\")\n",
    "    \n",
    "    print(\"------ TASK COMPLETED -------\")\n",
    "\n",
    "## spliting the data into train-test and creating train.txt and test.txt files\n",
    "# train_test_split('/content/drive/MyDrive/custom_notebooks/yolo_data/')\n",
    "\n",
    "### for label_tag\n",
    "train_test_split(dataset_source) ### without negative images\n",
    "# train_test_split('./data/','./negative_images/') ### if you want to feed negative images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now()\n",
    "\n",
    "yolo_detection_model='yolov8s.pt'\n",
    "dataset_config_path = dataset_folder + '/dataset.yaml'\n",
    "training_output_folder = dataset_folder + '/training_output'\n",
    "training_result_folder = 'result_yolov8s' + '_' + str(now.strftime(\"%Y%m%d_%H%M%S\"))\n",
    "training_result_path = os.path.join(training_output_folder, training_result_folder)\n",
    "\n",
    "print('yolo_detection_model: ', yolo_detection_model)\n",
    "print('dataset_config_path: ', dataset_config_path)\n",
    "print('training_output_folder: ', training_output_folder)\n",
    "print('training_result_folder: ', training_result_folder)\n",
    "print('training_result_path: ', training_result_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!yolo task=detect mode=train model={yolo_detection_model} data={dataset_config_path} epochs=50 imgsz=640 batch=8 project={training_output_folder} name={training_result_folder} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_model_path = os.path.join(training_output_folder, training_result_folder) + '/weights/best.pt'\n",
    "prediction_output_folder = dataset_folder + '/output/' + training_result_folder\n",
    "test_image_folder = dataset_folder + '/test'\n",
    "\n",
    "print('prediction_model_path: ', prediction_model_path)\n",
    "print('prediction_output_folder: ', prediction_output_folder)\n",
    "print('test_image_folder: ', test_image_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!yolo task=detect mode=predict model={prediction_model_path} conf=0.55 source={test_image_folder}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp -r /content/runs/detect/predict {prediction_output_folder}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validating Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from IPython.display import Image, display\n",
    "\n",
    "for image_path in glob.glob(f'{prediction_output_folder}/*.jpg')[:3]:\n",
    "      display(Image(filename=image_path, width=600))\n",
    "      print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
